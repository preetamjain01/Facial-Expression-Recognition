{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dw1aqRLMG1OA"
   },
   "source": [
    "# Facial Expression Recognition using ResNet - Part  3/3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zeYjEoCtG8hZ"
   },
   "source": [
    "## Abstract\n",
    "\n",
    "* In this part, we have implemented Residual Networks:\n",
    "    * Computer animated agents and robots bring new dimension in human computer interaction which makes it vital as how computers can affect our social life in day-to-day activities. Face to face communication is a real-time process operating at a time scale in the order of milliseconds. The level of uncertainty at this time scale is considerable, making it necessary for humans and machines to rely on sensory rich perceptual primitives rather than slow symbolic inference processes. In this project we are presenting the real time facial expression recognition of seven most basic human expressions: ANGER, DISGUST, FEAR, HAPPY, NEUTRAL, SAD, SURPRISE.\n",
    "\n",
    "\n",
    "### Dataset Introduction\n",
    "\n",
    "* The dataset we have chosen is Facial Expression Recognition fer2013.\n",
    "* The training set consists of 28,709 examples. The public test set consists of 3,589 examples. The final test set, consists of another 3,589 examples.\n",
    "* The data consists of 48x48 pixel grayscale images of faces. \n",
    "* The faces have been automatically registered so that the face is more or less centered and occupies about the same amount of space in each image. \n",
    "* The task is to categorize each face based on the emotion shown in the facial expression in to one of seven categories (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral).\n",
    "* The \"emotion\" column contains a numeric code ranging from 0 to 6, inclusive, for the emotion that is present in the image. The \"pixels\" column contains a string surrounded in quotes for each image. The contents of this string a space-separated pixel values in row major order. Our task is to predict the \"emotion\" column.\n",
    "* This dataset was prepared by Pierre-Luc Carrier and Aaron Courville, as part of an ongoing research project. They have graciously provided the workshop organizers with a preliminary version of their dataset to use for this contest.\n",
    "* Link to the dataset - https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data\n",
    "\n",
    "`Conclusion` - We train Residual Networks on certain parameters, resulting in the accuracy of `62.0%`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "alz-lmJlHBxH"
   },
   "source": [
    "### Part 3 - ResNet\n",
    "\n",
    "The core idea of ResNet is introducing a so-called “identity shortcut connection” that skips one or more layers. The authors argue that stacking layers shouldn’t degrade the network performance, because we could simply stack identity mappings (layer that doesn’t do anything) upon the current network, and the resulting architecture would perform the same. This indicates that the deeper model should not produce a training error higher than its shallower counterparts. They hypothesize that letting the stacked layers fit a residual mapping is easier than letting them directly fit the desired underlaying mapping. And the residual block above explicitly allows it to do precisely that.\n",
    "\n",
    "As a matter of fact, ResNet was not the first to make use of shortcut connections, Highway Network introduced gated shortcut connections. These parameterized gates control how much information is allowed to flow across the shortcut. Similar idea can be found in the Long Term Short Memory (LSTM) cell, in which there is a parameterized forget gate that controls how much information will flow to the next time step. Therefore, ResNet can be thought of as a special case of Highway Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorFlow:\n",
    "\n",
    "TensorFlow is an open source software library for high performance numerical computation. Its flexible architecture allows easy deployment of computation across a variety of platforms (CPUs, GPUs, TPUs), and from desktops to clusters of servers to mobile and edge devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "67J4SMCQFBrW",
    "outputId": "6ffd9414-fce9-43d8-bf16-6dfd5d60d151"
   },
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "tf.reset_default_graph() #This will reset the current loaded graph to avoid issues\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 56} ) #Providing GPU\n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* On a typical system, there are multiple computing devices. In TensorFlow, the supported device types are CPU and GPU. They are represented as strings. For example:\n",
    "\n",
    "    * \"/cpu:0\": The CPU of your machine.\n",
    "    * \"/device:GPU:0\": The GPU of your machine, if you have one.\n",
    "    * \"/device:GPU:1\": The second GPU of your machine, etc.\n",
    "If a TensorFlow operation has both CPU and GPU implementations, the GPU devices will be given priority when the operation is assigned to a device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hW5XW2TdFBra"
   },
   "outputs": [],
   "source": [
    "#read the dataset\n",
    "with open(\"../fer2013.csv\") as f:\n",
    "    content = f.readlines()\n",
    "#Converting lines to array as the lines represent the pixels\n",
    "lines = np.array(content)\n",
    "\n",
    "num_of_instances = lines.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The method readlines() reads until EOF using readline() and returns a list containing the lines.\n",
    "* Then np.array() creates an array of the list containing the lines from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6QpJdstCFBrd"
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = [], [], [], []\n",
    "\n",
    "#creating training and testing data [4]\n",
    "for i in range(1,num_of_instances):\n",
    "    emotion, img, usage = lines[i].split(\",\")\n",
    "    val = img.split(\" \")\n",
    "            \n",
    "    pixels = np.array(val, 'float32')\n",
    "        \n",
    "    emotion = keras.utils.to_categorical(emotion, 7)\n",
    "    #Creating training and testing set\n",
    "    if 'Training' in usage:\n",
    "        y_train.append(emotion)\n",
    "        x_train.append(pixels)\n",
    "    elif 'PublicTest' in usage:\n",
    "        y_test.append(emotion)\n",
    "        x_test.append(pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The split() method splits a string into a list by the given separator.\n",
    "* keras.utils.to_categorical() - Converts a class vector (integers) to binary class matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_903oL0DFBrf"
   },
   "outputs": [],
   "source": [
    "#Converting our training variables to NP array\n",
    "x_train = np.asarray(x_train, 'float32')\n",
    "y_train = np.asarray(y_train, 'float32')\n",
    "x_test = np.asarray(x_test, 'float32')\n",
    "y_test = np.asarray(y_test, 'float32')\n",
    "\n",
    "#Since the images are 48x48, reshaping the array to 48x48. And 1 is for grayscale and -1 will automatically detect the number of images.\n",
    "x_train = x_train.reshape([-1, 48, 48, 1])\n",
    "x_test = x_test.reshape([-1, 48, 48, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The np.asarray() method converts the given input to an array.\n",
    "* .reshape() - Reshapes the images in the array object to 48x48 without changing its data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "0Izd-uLGFBrg",
    "outputId": "93534ef1-fdb2-4bc7-8161-103e6484dcc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from tflearn.data_preprocessing import ImagePreprocessing\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Grx56pv2FBri"
   },
   "outputs": [],
   "source": [
    "#RealTime image preprocessing\n",
    "img_prep = ImagePreprocessing()\n",
    "\n",
    "# Zero Center (With mean computed over the whole dataset)\n",
    "img_prep.add_featurewise_zero_center()\n",
    "\n",
    "# STD Normalization (With standard deviation computed over the whole dataset)\n",
    "img_prep.add_featurewise_stdnorm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The model will preprocess the image using ImageDataPreocessing() library where the images are processed in real time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3DKLOEGlFBrk"
   },
   "outputs": [],
   "source": [
    "#This will augment the given image\n",
    "img_aug = tflearn.ImageAugmentation()\n",
    "#This will randomly flip the image for better training\n",
    "img_aug.add_random_flip_leftright()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The images will be augmented using ImageAugmentation() for better performance.\n",
    "* Then, the images will be flipped randomly to train it better and give better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "h1wKVAtdFBrm",
    "outputId": "e9c9955e-21ba-4996-8bd1-7124221c7b30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\tflearn\\initializations.py:119: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "WARNING:tensorflow:From C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\tflearn\\objectives.py:66: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "#Creating residual architecture\n",
    "n = 5  #[3]\n",
    "net = tflearn.input_data(shape=[None, 48, 48, 1], data_preprocessing=img_prep, data_augmentation=img_aug)\n",
    "net = tflearn.conv_2d(net, nb_filter=16, filter_size=3, regularizer='L2', weight_decay=0.0001)\n",
    "net = tflearn.residual_block(net, n, 16)\n",
    "net = tflearn.residual_block(net, 1, 32, downsample=True)\n",
    "net = tflearn.residual_block(net, n-1, 32)\n",
    "net = tflearn.residual_block(net, 1, 64, downsample=True)\n",
    "net = tflearn.residual_block(net, n-1, 64)\n",
    "# Normalizing the previous batches by converting activation function close to 0 and loss function close to 1\n",
    "net = tflearn.batch_normalization(net)\n",
    "net = tflearn.activation(net, 'relu')\n",
    "net = tflearn.global_avg_pool(net)\n",
    "    \n",
    "# Creating final layer\n",
    "net = tflearn.fully_connected(net, 7, activation='softmax')\n",
    "mom = tflearn.Momentum(learning_rate=0.1, lr_decay=0.0001, decay_step=32000, staircase=True, momentum=0.9)\n",
    "net = tflearn.regression(net, optimizer=mom,\n",
    "                         loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "VVil5CZ8FBrp",
    "outputId": "bec9186c-d7fe-4a5a-ab11-5874a0b36355"
   },
   "outputs": [],
   "source": [
    "model = tflearn.DNN(net, checkpoint_path='models/emotion_classification',\n",
    "                    max_checkpoints=20, tensorboard_verbose=0,\n",
    "                    clip_gradients=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "dWWKD8eJFBrr",
    "outputId": "b07c9af2-e4f0-4fd9-b7c2-0dd0347d9832"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from D:\\BDIA\\FinalProject_Team25\\ResNet\\resnet_emotion_1.tfl\n"
     ]
    }
   ],
   "source": [
    "#loading the previously trained model to retrain it\n",
    "model.load('resnet_emotion_1.tfl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "5n_b6UDnjwTF",
    "outputId": "d7e0de1f-a726-447e-dd34-8da10c2bf1b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 101249  | total loss: \u001b[1m\u001b[32m0.08673\u001b[0m\u001b[0m | time: 39.362s\n",
      "| Momentum | epoch: 100 | loss: 0.08673 - acc: 0.9746 -- iter: 28672/28709\n",
      "Training Step: 101250  | total loss: \u001b[1m\u001b[32m0.08696\u001b[0m\u001b[0m | time: 39.539s\n",
      "| Momentum | epoch: 100 | loss: 0.08696 - acc: 0.9748 -- iter: 28709/28709\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "model.fit(x_train,y_train, n_epoch = 200, snapshot_epoch = True, snapshot_step = 500,\n",
    "         show_metric=True, batch_size = 128, shuffle=True, run_id = \"200_emotion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Re-training the previously saved model by loading using model.load('resnet_emotion_1.tfl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5h1uCkX6B7RK"
   },
   "outputs": [],
   "source": [
    "#saving trained model\n",
    "model.save('resnet_emotion_1.tfl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZRbjljCFBru"
   },
   "outputs": [],
   "source": [
    "#evaluating the test score\n",
    "score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iGglhGX8H5R2",
    "outputId": "a9090298-a57f-4c11-b805-d7d444f255a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6202284759068828]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The test score after evaluation comes out to 62.0%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eIOx4GkxIBtm"
   },
   "outputs": [],
   "source": [
    "def detect_emotion(emotions):\n",
    "    \"\"\"\n",
    "    This function classifies the image by converting it NP into array and then predicting the results\n",
    "    \"\"\"\n",
    "    objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "    y_pos = np.arange(len(objects))\n",
    "    \n",
    "    plt.bar(y_pos, emotions, align='center', alpha=0.5)\n",
    "    plt.xticks(y_pos, objects)\n",
    "    plt.ylabel('percentage')\n",
    "    plt.title('emotion')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The above function classifies the input image by converting it into array and then predicts the results.\n",
    "* The np.arange(len(objects)) here returns evenly spaced value of length of objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 567
    },
    "colab_type": "code",
    "id": "icmm9B1nIvKq",
    "outputId": "2aa483fa-070e-47e9-fe7b-1cee5d77dc81"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:98: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = image.load_img(\"../d.jpg\", grayscale=True, target_size=(48, 48))\n",
    "\n",
    "x = image.img_to_array(img) #Converting image to array\n",
    "x = np.expand_dims(x, axis = 0) #This will expand the shape of an array as we already converted the input image to 48x48\n",
    "\n",
    "emotion_prediction = model.predict(x)\n",
    "detect_emotion(emotion_prediction[0])\n",
    "\n",
    "x = np.array(x, 'float32')\n",
    "x = x.reshape([48, 48]);\n",
    "\n",
    "plt.gray()\n",
    "plt.imshow(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* img_to_array() - Converts the image to array\n",
    "* np.expand_dims() - Expands the shape of an array. Insert a new axis that will appear at the axis = 0 position in the expanded array shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCV:\n",
    "\n",
    "OpenCV (Open Source Computer Vision) is a library of programming functions mainly aimed at real-time computer vision. The C++ API provides a class ‘videocapture’ for capturing video from cameras or for reading video files and image sequences. It is basically used to access the Webcam of our computer to capture real-time videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7YKjdnpbREMn"
   },
   "outputs": [],
   "source": [
    "#Detecing expessions by feeding a video or webcam\n",
    "import cv2\n",
    "from collections import deque\n",
    "import operator\n",
    "emotion_queue = deque(maxlen=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jGO55jV_RULg"
   },
   "outputs": [],
   "source": [
    "def smooth_emotions(prediction):\n",
    "    \"\"\"\n",
    "    As the model will provide the mixture of results this function will give average of the emotions to 1 emotion\n",
    "    \n",
    "    \"\"\"\n",
    "    emotions = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]\n",
    "    emotion_values = {'Angry': 0.0, 'Disgust': 0.0, 'Fear': 0.0, 'Happy': 0.0, 'Sad': 0.0, 'Surprise': 0.0, 'Neutral': 0.0}\n",
    "\n",
    "    emotion_probability, emotion_index = max((val, idx) for (idx, val) in enumerate(prediction[0]))\n",
    "    emotion = emotions[emotion_index]\n",
    "\n",
    "    # Append the new emotion and if the max length is reached pop the oldest value out\n",
    "    emotion_queue.appendleft((emotion_probability, emotion))\n",
    "\n",
    "    # Iterate through each emotion in the queue and create an average of the emotions\n",
    "    for pair in emotion_queue:\n",
    "        emotion_values[pair[1]] += pair[0]\n",
    "\n",
    "    # Select the current emotion based on the one that has the highest value\n",
    "    average_emotion = max(emotion_values.items(), key=operator.itemgetter(1))[0]\n",
    "    return average_emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The above function takes processed image as input and provides the average of the emotions to 1 emotion from the mixture of results provided by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d3Yig5sxRXBg"
   },
   "outputs": [],
   "source": [
    "# preprocessing the input image\n",
    "def process_image(roi_gray, img):\n",
    "        image_scaled = np.array(cv2.resize(roi_gray, (48, 48)), dtype=float)\n",
    "        image_processed = image_scaled.flatten()\n",
    "        image_processed = image_processed.reshape([-1, 48, 48, 1])\n",
    "\n",
    "        prediction = model.predict(image_processed)\n",
    "        emotion = smooth_emotions(prediction)\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img, \"Emotion: \" + emotion, (50, 450), font, 1, (0, 255, 255), 2)\n",
    "        cv2.imshow('img', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The above function performs a series of preprocessing steps on input image by reshaping and flattening. Then it feeds the processed image to the model for it to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting objects through webcam\n",
    "\n",
    "The below code is used to detect objects through webcam. To capture a video, we need to create a VideoCapture object. Its argument can be either the device index or the name of a video file. Device index is just the number to specify which camera. Normally one camera will be connected (as in my case). So I simply pass 0 (or -1). You can select the second camera by passing 1 and so on. After that, you can capture frame-by-frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9kATb_L4RXxi"
   },
   "outputs": [],
   "source": [
    "# detecting human faces using HAAR cascade [1]\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "cap = cv2.VideoCapture(0) # 0 for webcam\n",
    "#cap = cv2.VideoCapture(\"../face_detection.mp4\") # input the name of your video file here\n",
    "\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        roi_gray = gray[y:y + h, x:x + w]\n",
    "        roi_color = img[y:y + h, x:x + w]\n",
    "        process_image(roi_gray, img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YTtn1EYJIJYu"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "* We trained our model on 32 layers and around 700 epochs and still the model doesn’t overfit and improved continuously.\n",
    "\n",
    "* Below table summarizes the values and the score that we could produce using the respective combination.\n",
    " \n",
    "Model No. | training accuracy | testing accuracy\n",
    "-----------------|----------------|----------------------\n",
    "CNN Sequential  | 99.7 %          | 57.2%       \n",
    "VGG19 | 99.3 % | 58.0%\n",
    "ResNet | 97.4 % | 62.0 %\n",
    "\n",
    "* ResNet produced the testing accuracy of 62% (Highest in our case). We can improve it more by training it again for some more time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7G99P38-I4H1"
   },
   "source": [
    "## Contribution\n",
    "\n",
    "In the above analysis:\n",
    "\n",
    "- 60% of the work is done by us which includes\n",
    "  * ResNet implementation\n",
    "  * Live webcam code optimization\n",
    "\n",
    "- 40% of the work is taken from web, the links for which are cited below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xRFpGjmFI-V2"
   },
   "source": [
    "## Citations\n",
    "\n",
    "1. For face detection - https://www.youtube.com/watch?v=PmZ29Vta7Vc\n",
    "\n",
    "2. For VGG19 and ResNet - https://github.com/tflearn/tflearn/tree/master/examples/images\n",
    "\n",
    "3. For tflearn - http://tflearn.org/tutorials/\n",
    "\n",
    "4. Article on Facial Emotion Recognition using CNN - http://sefiks.com/2018/01/01/facial-expression-recognition-with-keras/\n",
    "\n",
    "5. VGG19 CNN - https://www.mathworks.com/help/deeplearning/ref/vgg19.html;jsessionid=ccf9599bd865b423281a56299a68"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S8R1rDrcJCxm"
   },
   "source": [
    "\n",
    "<font size=\"4\">MIT License</font>\n",
    "    \n",
    "<b>Copyright (c) 2019 RUPESH ACHARYA, PREETAM JAIN</b>\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ResNet_Model.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
