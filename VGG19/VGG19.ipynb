{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lIxe1pZ5ySzt"
   },
   "source": [
    "# Facial Expression Recognition using VGG19 - Part  2/3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "toU-JucSzcNr"
   },
   "source": [
    "## Abstract\n",
    "\n",
    "* In this part, we used VGG19 Convolutional Neural Network model for getting the best testing accuracy to see how good will our model predict the expressions on human faces and categorize them into one of seven categories (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral)\n",
    "\n",
    "### Dataset Introduction\n",
    "\n",
    "* The dataset we have chosen is Facial Expression Recognition fer2013. The data consists of 48x48 pixel grayscale images of faces. The faces have been automatically registered so that the face is more or less centered and occupies about the same amount of space in each image. The task is to categorize each face based on the emotion shown in the facial expression in to one of seven categories (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral).\n",
    "\n",
    "* The \"emotion\" column contains a numeric code ranging from 0 to 6, inclusive, for the emotion that is present in the image. The \"pixels\" column contains a string surrounded in quotes for each image. The contents of this string a space-separated pixel values in row major order. Our task is to predict the \"emotion\" column.\n",
    "\n",
    "* The training set consists of 28,709 examples. The public test set consists of 3,589 examples. The final test set, consists of another 3,589 examples.\n",
    "\n",
    "* This dataset was prepared by Pierre-Luc Carrier and Aaron Courville, as part of an ongoing research project. They have graciously provided the workshop organizers with a preliminary version of their dataset to use for this contest.\n",
    "\n",
    "* Link to the dataset - https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data\n",
    "\n",
    "`Conclusion` - We trained VGG19 model here, resulting in the accuracy of `58.0%`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J-n26KAF6sJ5"
   },
   "source": [
    "### Part 2 - VGG19\n",
    "\n",
    "* VGG-19 is a convolutional neural network that is trained on more than a million images from the ImageNet database. The network is 19 layers deep and can classify images into 1000 object categories, such as keyboard, mouse, pencil, and many animals. As a result, the network has learned rich feature representations for a wide range of images. The network has an image input size of 224-by-224.\n",
    "* We will be using VGG-19 pre-trained through ImageNet. ImageNet is a large visual database covering over 14 million URLs of images and more than 20 thousand ambiguous categories which helps to cover more diverse feature when it comes to natural images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFLearn:\n",
    "\n",
    "TFlearn is a modular and transparent deep learning library built on top of Tensorflow. It was designed to provide a higher-level API to TensorFlow in order to facilitate and speed-up experimentations, while remaining fully transparent and compatible with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "bQOUz78xQZtx",
    "outputId": "f99a626a-5860-44ea-f684-f16085e5f87f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from tflearn.data_preprocessing import ImagePreprocessing\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hy5AUbimQZt2"
   },
   "outputs": [],
   "source": [
    "#read the dataset\n",
    "with open(\"../fer2013.csv\") as f:\n",
    "    content = f.readlines()\n",
    "#Converting lines to array as the lines represent the pixels\n",
    "lines = np.array(content)\n",
    "\n",
    "num_of_instances = lines.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The method readlines() reads until EOF using readline() and returns a list containing the lines.\n",
    "* Then np.array() creates an array of the list containing the lines from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WMqt63DTQZt4"
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = [], [], [], []\n",
    "\n",
    "#creating training and testing data [4]\n",
    "for i in range(1,num_of_instances):\n",
    "    emotion, img, usage = lines[i].split(\",\")\n",
    "    val = img.split(\" \")\n",
    "            \n",
    "    pixels = np.array(val, 'float32')\n",
    "        \n",
    "    emotion = keras.utils.to_categorical(emotion, 7)\n",
    "    #Creating training and testing set\n",
    "    if 'Training' in usage:\n",
    "        y_train.append(emotion)\n",
    "        x_train.append(pixels)\n",
    "    elif 'PublicTest' in usage:\n",
    "        y_test.append(emotion)\n",
    "        x_test.append(pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The split() method splits a string into a list by the given separator.\n",
    "* keras.utils.to_categorical() - Converts a class vector (integers) to binary class matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dkmcykzcQZt5"
   },
   "outputs": [],
   "source": [
    "#Converting our training variables to NP array\n",
    "x_train = np.asarray(x_train, 'float32')\n",
    "y_train = np.asarray(y_train, 'float32')\n",
    "x_test = np.asarray(x_test, 'float32')\n",
    "y_test = np.asarray(y_test, 'float32')\n",
    "\n",
    "#Since the images are 48x48, reshaping the array to 48x48. And 1 is for grayscale and -1 will automatically detect the number of images.\n",
    "x_train = x_train.reshape([-1, 48, 48, 1])\n",
    "x_test = x_test.reshape([-1, 48, 48, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The np.asarray() method converts the given input to an array.\n",
    "* .reshape() - Reshapes the images in the array object to 48x48 without changing its data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "PWeIOLVbQZt9",
    "outputId": "51259ad4-1ecc-43bb-8d87-ef6d9bd4c9d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/initializations.py:119: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/layers/core.py:239: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/objectives.py:66: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "\n",
    "# Building 'VGG Network'\n",
    "network = input_data(shape=[None, 48, 48, 1])\n",
    "\n",
    "network = conv_2d(network, 64, 3, activation='relu')\n",
    "network = conv_2d(network, 64, 3, activation='relu')\n",
    "network = max_pool_2d(network, 2, strides=2)\n",
    "\n",
    "network = conv_2d(network, 128, 3, activation='relu')\n",
    "network = conv_2d(network, 128, 3, activation='relu')\n",
    "network = max_pool_2d(network, 2, strides=2)\n",
    "\n",
    "network = conv_2d(network, 256, 3, activation='relu')\n",
    "network = conv_2d(network, 256, 3, activation='relu')\n",
    "network = conv_2d(network, 256, 3, activation='relu')\n",
    "network = max_pool_2d(network, 2, strides=2)\n",
    "\n",
    "network = conv_2d(network, 512, 3, activation='relu')\n",
    "network = conv_2d(network, 512, 3, activation='relu')\n",
    "network = conv_2d(network, 512, 3, activation='relu')\n",
    "network = max_pool_2d(network, 2, strides=2)\n",
    "\n",
    "network = conv_2d(network, 512, 3, activation='relu')\n",
    "network = conv_2d(network, 512, 3, activation='relu')\n",
    "network = conv_2d(network, 512, 3, activation='relu')\n",
    "network = max_pool_2d(network, 2, strides=2)\n",
    "\n",
    "network = fully_connected(network, 1024, activation='relu')\n",
    "network = dropout(network, 0.5)\n",
    "network = fully_connected(network, 1024, activation='relu')\n",
    "network = dropout(network, 0.5)\n",
    "network = fully_connected(network, 7, activation='softmax')\n",
    "\n",
    "network = regression(network, optimizer='rmsprop',\n",
    "                     loss='categorical_crossentropy',\n",
    "                     learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "UlxEKq_JQZuA",
    "outputId": "7357489f-68f4-4369-9d80-49136cb71e96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model = tflearn.DNN(network, checkpoint_path='model_vgg',\n",
    "                    max_checkpoints=1, tensorboard_verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "bdFWF-shmC-4",
    "outputId": "e454946c-2cfc-4cf3-8d86-c0e87b6e231d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /content/vgg19_final.tfl\n"
     ]
    }
   ],
   "source": [
    "#loading the previously trained model to retrain it\n",
    "model.load('vgg19_emotion.tfl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "HiQ8CUtfllmf",
    "outputId": "44c3f0a4-92b7-446e-aa2f-f2c1f19f0a83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 67499  | total loss: \u001b[1m\u001b[32m0.05512\u001b[0m\u001b[0m | time: 24.189s\n",
      "| RMSProp | epoch: 200 | loss: 0.05512 - acc: 0.9936 -- iter: 28672/28709\n",
      "Training Step: 67500  | total loss: \u001b[1m\u001b[32m0.05089\u001b[0m\u001b[0m | time: 24.298s\n",
      "| RMSProp | epoch: 200 | loss: 0.05089 - acc: 0.9935 -- iter: 28709/28709\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "model.fit(x_train, y_train, n_epoch=200, shuffle=True,\n",
    "          show_metric=True, batch_size=128, snapshot_step=20,\n",
    "          snapshot_epoch=False, run_id='vgg_emotion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Retraining the loaded model by tuning the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LxuWsFmPQZuC",
    "outputId": "f6134ac9-81b4-4767-bda8-fcd4eaac3a38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuarcy:  [0.5801058790791032]\n"
     ]
    }
   ],
   "source": [
    "#evaluating the testing score\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test accuarcy: ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Evaluating the Testing accuracy which comes to 58.0%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OZTmzN7JfbjG"
   },
   "outputs": [],
   "source": [
    "#save the trained model\n",
    "model.save('vgg19_emotion.tfl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Saving the trained model here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lvy6V7iyQZuE"
   },
   "outputs": [],
   "source": [
    "def detect_emotion(emotions):\n",
    "    \"\"\"\n",
    "    This function classifies the image by converting it NP into array and then predicting the results\n",
    "    \"\"\"\n",
    "    objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "    y_pos = np.arange(len(objects))\n",
    "\n",
    "    plt.bar(y_pos, emotions, align='center', alpha=0.5)\n",
    "    plt.xticks(y_pos, objects)\n",
    "    plt.ylabel('percentage')\n",
    "    plt.title('emotion')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The above function classifies the input image by converting it into array and then predicts the results.\n",
    "* The np.arange(len(objects)) here returns evenly spaced value of length of objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WCAxudiGQZuG"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 567
    },
    "colab_type": "code",
    "id": "muiYg2g5QZuI",
    "outputId": "5db94a77-9720-4b70-cca9-0efcc4b8d647"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py:98: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEICAYAAACwDehOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAF3RJREFUeJzt3Xm4JXV95/H3h21AwUbtjoZFL2iD\nQWJcWhCXGVxQJAomYoRAFMPI40xwTeYRIyLBZTTmiT6OuEDkIYCKoEPsmFZEAgE1KA3IPpBOA9Jo\npEHZJdDwnT+qbnG43OX07Vv30PT79TznuVV1flX1PXXrnM+p9aSqkCQJYKNRFyBJevQwFCRJHUNB\nktQxFCRJHUNBktQxFCRJHUNBmgdJvpPkraOuQ5pJvE5BmltJjgaeWVUHj7oWaW25pSBJ6hgK2qAk\n2SbJN5OsTnJdkne1w49OcnqSU5LcmeTyJDsl+UCSm5PcmOTVE6azNMmvkqxI8vZ2+N7AXwJvTnJX\nkkvb4ecm+e9t90ZJjkxyQzvtk5IsaJ8bS1JJ3prkZ0luSfLB+V5O2nAZCtpgJNkI+EfgUmBb4JXA\ne5K8pm3yeuBk4InAJcCZNO+RbYFjgC8NTO5UYBWwDbA/8PEkr6iq7wIfB75eVVtW1e9NUsoh7ePl\nwI7AlsDnJrR5KbBzW+NRSX5n1i9cWguGgjYkLwQWVdUxVXVfVa0EjgcOaJ8/v6rOrKo1wOnAIuAT\nVXU/TQiMJdk6yfbAS4D3V9W9VfVT4O+AtwxZx0HA31bVyqq6C/gAcECSTQba/FVV/aaqLqUJscnC\nRZpzm8zcRHrMeDqwTZLbBoZtDJwP3AD8cmD4b4BbquqBgX5ovtVvA/yqqu4caH8DsGTIOrZp2w+O\nuwnwlIFh/zHQfU87X6l3biloQ3IjcF1VbT3w2Kqq9lnL6fwceFKSrQaGPQ24qe2e6ZS+n9ME1OC4\na3h4KEkjYShoQ/IT4M4k70+yRZKNk+ya5IVrM5GquhH4EfC/k2ye5DnAocApbZNf0uxqmur99TXg\nvUl2SLIlDx2DWDOrVyXNIUNBG4x2V9DrgOcC1wG30BwLWDCLyR0IjNF86z8D+HBVfb997vT2761J\nLp5k3BNoDmif19ZxL/DOWdQgzTkvXpMkddxSkCR1DAVJUsdQkCR1DAVJUme9u3ht4cKFNTY2Nuoy\nJGm9ctFFF91SVYtmarfehcLY2BjLly8fdRmStF5JcsPMrXrcfZTkhPYOkFdM8XySfLa9w+RlSZ7f\nVy2SpOH0eUzhRGDvaZ5/LbC4fRwGfKHHWiRJQ+gtFKrqPOBX0zTZDzipGhcAWyf57b7qkSTNbJRn\nH21Lc4OycavaYY+Q5LAky5MsX7169bwUJ0kbovXilNSqOq6qllTVkkWLZjx4LkmapVGGwk3A9gP9\n2/HQrYclSSMwylBYCrylPQvpRcDtVfWLEdYjSRu83q5TSPI1YE9gYZJVwIeBTQGq6ovAMmAfYAXN\nL0u9ra9aJEnD6S0UqurAGZ4v4M/6mr8kae2td1c0r4tPn3XtqEt4mPfutdOoS5Ckh1kvzj6SJM0P\nQ0GS1DEUJEkdQ0GS1DEUJEkdQ0GS1DEUJEkdQ0GS1DEUJEkdQ0GS1DEUJEkdQ0GS1DEUJEkdQ0GS\n1DEUJEkdQ0GS1DEUJEkdQ0GS1DEUJEkdQ0GS1DEUJEkdQ0GS1DEUJEkdQ0GS1DEUJEkdQ0GS1DEU\nJEkdQ0GS1DEUJEkdQ0GS1DEUJEkdQ0GS1Ok1FJLsneSaJCuSHDHJ809Lck6SS5JclmSfPuuRJE2v\nt1BIsjFwLPBaYBfgwCS7TGh2JHBaVT0POAD4fF/1SJJm1ueWwm7AiqpaWVX3AacC+01oU8AT2u4F\nwM97rEeSNINNepz2tsCNA/2rgN0ntDka+F6SdwKPB17VYz2SpBmM+kDzgcCJVbUdsA9wcpJH1JTk\nsCTLkyxfvXr1vBcpSRuKPkPhJmD7gf7t2mGDDgVOA6iqfwU2BxZOnFBVHVdVS6pqyaJFi3oqV5LU\nZyhcCCxOskOSzWgOJC+d0OZnwCsBkvwOTSi4KSBJI9JbKFTVGuBw4EzgapqzjK5MckySfdtmfw68\nPcmlwNeAQ6qq+qpJkjS9Pg80U1XLgGUThh010H0V8JI+a5AkDW/UB5olSY8ihoIkqWMoSJI6hoIk\nqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMo\nSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6\nhoIkqTN0KCR5aZK3td2LkuzQX1mSpFEYKhSSfBh4P/CBdtCmwCl9FSVJGo1htxT+ANgXuBugqn4O\nbNVXUZKk0Rg2FO6rqgIKIMnj+ytJkjQqw4bCaUm+BGyd5O3A94HjZxopyd5JrkmyIskRU7T5oyRX\nJbkyyVeHL12SNNc2GaZRVf1Nkr2AO4CdgaOq6qzpxkmyMXAssBewCrgwydKqumqgzWKa4xQvqapf\nJ/mtWb4OSdIcGCoUANoQmDYIJtgNWFFVKwGSnArsB1w10ObtwLFV9et2HjevxfQlSXNs2LOP7kxy\nx4THjUnOSLLjFKNtC9w40L+qHTZoJ2CnJD9MckGSvaeY/2FJlidZvnr16mFKliTNwrBbCp+h+VD/\nKhDgAOAZwMXACcCe6zD/xe342wHnJfndqrptsFFVHQccB7BkyZKa5bwkSTMY9kDzvlX1paq6s6ru\naD+kX1NVXweeOMU4NwHbD/Rv1w4btApYWlX3V9V1wLU0ISFJGoFhQ+Ge9iyhjdrHHwH3ts9N9c39\nQmBxkh2SbEazdbF0Qpt/oN3KSLKQZnfSyrV5AZKkuTNsKBwE/AlwM/DLtvvgJFsAh082QlWtaZ87\nE7gaOK2qrkxyTJJ922ZnArcmuQo4B/hfVXXrrF+NJGmdDHtK6krg9VM8/YNpxlsGLJsw7KiB7gLe\n1z4kSSM2VCgk2Rw4FHg2sPn48Kr6057qkiSNwLC7j04Gngq8BvgXmoPGd/ZVlCRpNIYNhWdW1YeA\nu6vq74HfB3bvryxJ0igMGwr3t39vS7IrsADwlhSS9Bgz7MVrxyV5InAkzWmlWwIf6q0qSdJIDBsK\nZ7f3JzoP2BHAX16TpMeeYXcffXOSYd+Yy0IkSaM37ZZCkmfRnIa6IMkfDjz1BAZOTZUkPTbMtPto\nZ+B1wNY8/OK1O2luey1JegyZNhSq6lvAt5LsUVX/Ok81SZJGZNgDzSuS/CUwNjiOVzRL0mPLsKHw\nLeB8mt9mfqC/ciRJozRsKDyuqt7fayWSpJEb9pTUbyfZp9dKJEkjN2wovJsmGO5tf5/5ziR39FmY\nJGn+Dft7Clv1XYgkafSG2lJI4+AkH2r7t0+yW7+lSZLm27C7jz4P7AH8cdt/F3BsLxVJkkZm2LOP\ndq+q5ye5BKCqfp1ksx7rkiSNwNC/p5BkY6AAkiwCHuytKknSSAwbCp8FzgB+K8nHgB8AH++tKknS\nSAx79tFXklwEvBII8IaqurrXyiRJ826oUEjyIuDKqjq27X9Ckt2r6se9VidJmlfD7j76As0ZR+Pu\naodJkh5Dhg2FVFWN91TVgwx/5pIkaT0xbCisTPKuJJu2j3cDK/ssTJI0/4YNhXcALwZuAlYBuwOH\n9VWUJGk0ZtwF1F6fcFBVHTAP9UiSRmjGLYWqegA4cB5qkSSN2LAHi3+Y5HPA14G7xwdW1cW9VCVJ\nGolhQ+G57d9jBoYV8Iq5LUeSNErDXtH88r4LkSSN3rC/p/CUJF9O8p22f5ckh/ZbmiRpvg17SuqJ\nwJnANm3/tcB7+ihIkjQ6w4bCwqo6jfZ22VW1BnhgppGS7J3kmiQrkhwxTbs3JqkkS4asR5LUg2FD\n4e4kT+ah31N4EXD7dCO01zccC7wW2AU4MMkuk7TbCng34M31JGnEhg2F9wFLgR2T/BA4CXjnDOPs\nBqyoqpVVdR9wKrDfJO0+AnwSuHfIWiRJPRk2FK6i+ZGdC4FfAsfTHFeYzrbAjQP9q9phnSTPB7av\nqn+abkJJDkuyPMny1atXD1myJGltDRsKJwHPovm1tf8D7AScvC4zTrIR8LfAn8/UtqqOq6olVbVk\n0aJF6zJbSdI0hr14bdeqGjwecE6Sq2YY5yZg+4H+7dph47YCdgXOTQLwVGBpkn2ravmQdUmS5tCw\nWwoXtweXAUiyOzDTB/eFwOIkOyTZDDiA5rgEAFV1e1UtrKqxqhoDLgAMBEkaoWG3FF4A/CjJz9r+\npwHXJLkcqKp6zsQRqmpNksNprm/YGDihqq5McgywvKqWThxHkjRaw4bC3rOZeFUtA5ZNGHbUFG33\nnM08JElzZ9h7H93QdyGSpNEb9piCJGkDYChIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqG\ngiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSp\nYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjq9hkKSvZNc\nk2RFkiMmef59Sa5KclmSs5M8vc96JEnT6y0UkmwMHAu8FtgFODDJLhOaXQIsqarnAN8A/rqveiRJ\nM+tzS2E3YEVVrayq+4BTgf0GG1TVOVV1T9t7AbBdj/VIkmbQZyhsC9w40L+qHTaVQ4HvTPZEksOS\nLE+yfPXq1XNYoiRp0KPiQHOSg4ElwKcme76qjquqJVW1ZNGiRfNbnCRtQDbpcdo3AdsP9G/XDnuY\nJK8CPgj8t6r6zx7rkSTNoM8thQuBxUl2SLIZcACwdLBBkucBXwL2raqbe6xFkjSE3kKhqtYAhwNn\nAlcDp1XVlUmOSbJv2+xTwJbA6Ul+mmTpFJOTJM2DPncfUVXLgGUThh010P2qPucvSVo7j4oDzZKk\nRwdDQZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSR1D\nQZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSR1DQZLU\nMRQkSR1DQZLUMRQkSR1DQZLUMRQkSZ1NRl2AHns+fda1oy7hYd67106jLkFab7ilIEnqGAqSpE6v\noZBk7yTXJFmR5IhJnv8vSb7ePv/jJGN91iNJml5voZBkY+BY4LXALsCBSXaZ0OxQ4NdV9Uzg08An\n+6pHkjSzPrcUdgNWVNXKqroPOBXYb0Kb/YC/b7u/AbwySXqsSZI0jT7PPtoWuHGgfxWw+1RtqmpN\nktuBJwO3DDZKchhwWNt7V5Jreql4eAuZUONsvG8OClkLc1LzPFvflvMGu4znmTXPztOHabRenJJa\nVccBx426jnFJllfVklHXsTasuX/rW71gzfNlfaq5z91HNwHbD/Rv1w6btE2STYAFwK091iRJmkaf\noXAhsDjJDkk2Aw4Alk5osxR4a9u9P/DPVVU91iRJmkZvu4/aYwSHA2cCGwMnVNWVSY4BllfVUuDL\nwMlJVgC/ogmO9cGjZlfWWrDm/q1v9YI1z5f1pub4xVySNM4rmiVJHUNBktQxFNYzSY5O8hdJjkny\nqnmY3xsmuRJ9Lqb7riRXJ/nKXE97XSUZS3LFqOsYpfVxGSRZlmTrUdcxlXaZ/vEsx71rruuZiqEw\nx9pTa3tXVUdV1ffnYVZvoLlNyVz7n8BeVXXQbCcwX8taozHs/zeNjapqn6q6re+61sEYMGkoPJrW\n5Q0+FJL8Q5KLklzZXjlNkruSfCzJpUkuSPKUdvgz2v7Lk3x0PL2T7Jnk/CRLgavab/HvGZjHx5K8\nex1q/GCSa5P8ANi5HXZikv3b7k8kuSrJZUn+Zohavz0w7c8lOWSy6SR5MbAv8KkkP03yjNm+hgmv\n54vAjsB32td2QpKfJLkkyX5tm7F2mV7cPl48UH+3rOeinilsnOT4dr34XpItkrw9yYXtevHNJI9r\nazoxyReTLG//T69rhx+S5FtJzk3yb0k+3A6f0/VjOkken+Sf2pqvSPLmJEe1r+OKJMclza1lkryg\nbXcp8Gc913B9koXt80uSnNt2H53k5CQ/pDkzcaplOJbmZpsnAVcA249Pc7L5Dby+f2nf72cm+e0h\n6x9Ls1U7cX14RpLvttM7P8mz2vbde7PtH/+W/wngZe176b3ta1ua5J+Bs5NsmeTsdn2/fPy9MO+q\naoN+AE9q/25Bs3I9GSjg9e3wvwaObLu/DRzYdr8DuKvt3hO4G9ih7R8DLm67NwL+HXjyLOt7AXA5\n8DjgCcAK4C+AE2mu7XgycA0PnUm29RC1fntg+p8DDplmOicC+/ew3K+nufT/48DB4/MErgUe377e\nzdvhi2lOY37Esu5pnRgD1gDPbftPAw4e/B8CHwXeObCMvtv+rxfT3NJl83a5/qJdtuPr15K5XD+G\neC1vBI4f6F8wvs63/ScPrOuXAf+17f4UcEWPNVwPLGz7lwDntt1HAxcBW7T90y3DB4EXTbJOTTa/\nTYEfAYvaYW+mOU1+XdaHs4HF7bDdaa6zesR7hqnfe4e068r4Z9AmwBPa7oU07/UMTmM+Hhv8lgLw\nrvab0QU0V1cvBu6j+VCFZgUda7v3AE5vu786YTo/qarrAKrqeuDWJM8DXg1cUlWzvVL7ZcAZVXVP\nVd3BIy8AvB24F/hykj8E7hmi1slMNZ2+vRo4IslPgXNpPkyfRvMmPj7J5TSvY3AXVrese3RdVf20\n7R5fB3ZtvxFeDhwEPHug/WlV9WBV/RuwEnhWO/ysqrq1qn4D/F/gpXO8fszkcmCvJJ9M8rKquh14\neZpb1V8OvAJ4dpp98VtX1XnteCf3XMN0lrbLa9wjlmE7/IaqumDI+e0M7Aqc1a5rR9LcZWFYk60P\nLwZOb6f3JWCoLY8JzqqqX7XdAT6e5DLg+zT3hnvKLKa5Th41+7FGIcmewKuAParqnnYTdnPg/mrj\nGXiA4ZbT3RP6/47mm8BTgRPmot7JVHOR4G7AK2m2HA6neaNPZQ0P3224+SynM1cCvLGqHnaTwyRH\nA78Efq+t996Bpycu6z7850D3AzTfUk8E3lBVl6bZ5bbnQJuJF/zUDMPna/24NsnzgX2AjyY5m2bX\n0JKqurFdzpv3Nf9pahhcDyfOf+L/d6plOOl6MMX8zgCurKo9ZvkyJq4PTwFuq6rnTtK2e21JNgI2\nm2a6g6/hIGAR8IKquj/J9fT8v5nMhr6lsIDm9xzuafcHvmiG9hfQbJrCzFdfnwHsDbyQ5qru2ToP\neEO7D3Mr4PWDTybZElhQVcuA99J8iE5X6w3ALml+4GhrmhCYbjp3AlutQ/0zORN458B+7ee1wxcA\nv6iqB4E/obkqftS2An6RZFOaN/CgNyXZKM1xlx1pdsVB8431SUm2oDlo/8N2+FytH9NKsg1wT1Wd\nQrNL6PntU7e0//P9Aao5QHtbkvFv4bM+AWDIGq6n2TUKD62nU5lqGa7N/K4BFiXZo22zaZJnTzOZ\nmdwBXJfkTe30kmT8PXM9D722fWm2emHm99IC4OY2EF7OkHc1nWsb9JYCzX7gdyS5mmalmWxTdNB7\ngFOSfLAdd8rN4Kq6L8k5NN8mHphtgVV1cZKvA5cCN9PcU2rQVsC3kmxO8617/E7Rk9bafjs8jWbf\n7HXAJTNM51Sa3TjvotlP+u+zfS1T+AjwGeCy9lvVdcDrgM8D30zylrb++dg6mMmHgB8Dq9u/g2/w\nnwE/oTnu846qurfNuZ8A36TZVXFKVS2HuVs/hvC7NCcKPAjcD/wPmg/WK4D/4OHr09uAE5IU8L2e\na9iCZlflR2h2G07nEcsw0/9K4yPm1y7v/YHPJllA89n3GeDKWb+qJji/kORImg/+U2nep8fTvJcu\n5eHr7mXAA+3wE4FfT5jeV4B/bHfrLQf+3zrUNmve5mItpDnb5DdVVUkOoDmQO+kZAu0H3MXAm9r9\nzPNqbWrVuklyIs0BxG9MGH4IzW6awycZZ6Trx/piumWofmzoWwpr6wXA59pdHbcBfzpZozQXe32b\n5gDxqN7wQ9Wq+fcoWT+kSbmlIEnqbOgHmiVJAwwFSVLHUJAkdQwFSVLHUJAkdf4/yLhz5Cc1Uh8A\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxAvfmAb5fyVD2G95S/bLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = image.load_img(\"angryface.jpeg\", grayscale=True, target_size=(48, 48))\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "\n",
    "x = x.flatten()\n",
    "x = x.reshape([-1, 48, 48, 1])\n",
    "\n",
    "emotion_prediction = model.predict(x)\n",
    "detect_emotion(emotion_prediction[0])\n",
    "\n",
    "x = np.array(x, 'float32')\n",
    "x = x.reshape([48, 48]);\n",
    "\n",
    "plt.gray()\n",
    "plt.imshow(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* img_to_array() - Converts the image to array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCV:\n",
    "\n",
    "OpenCV (Open Source Computer Vision) is a library of programming functions mainly aimed at real-time computer vision. The C++ API provides a class ‘videocapture’ for capturing video from cameras or for reading video files and image sequences. It is basically used to access the Webcam of our computer to capture real-time videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cYY6SoYaSHHq"
   },
   "outputs": [],
   "source": [
    "#Detecing expessions by feeding a video or webcam\n",
    "import cv2\n",
    "from collections import deque\n",
    "import operator\n",
    "emotion_queue = deque(maxlen=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zx2nAA7ySJjK"
   },
   "outputs": [],
   "source": [
    "# calculate the avearge emotion\n",
    "def smooth_emotions(prediction):\n",
    "    \"\"\"\n",
    "    As the model will provide the mixture of results this function will give average of the emotions to 1 emotion\n",
    "    \n",
    "    \"\"\"\n",
    "    emotions = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]\n",
    "    emotion_values = {'Angry': 0.0, 'Disgust': 0.0, 'Fear': 0.0, 'Happy': 0.0, 'Sad': 0.0, 'Surprise': 0.0, 'Neutral': 0.0}\n",
    "\n",
    "    emotion_probability, emotion_index = max((val, idx) for (idx, val) in enumerate(prediction[0]))\n",
    "    emotion = emotions[emotion_index]\n",
    "\n",
    "    # Append the new emotion and if the max length is reached pop the oldest value out\n",
    "    emotion_queue.appendleft((emotion_probability, emotion))\n",
    "\n",
    "    # Iterate through each emotion in the queue and create an average of the emotions\n",
    "    for pair in emotion_queue:\n",
    "        emotion_values[pair[1]] += pair[0]\n",
    "\n",
    "    # Select the current emotion based on the one that has the highest value\n",
    "    average_emotion = max(emotion_values.items(), key=operator.itemgetter(1))[0]\n",
    "    return average_emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The above function takes processed image as input and provides the average of the emotions to 1 emotion from the mixture of results provided by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DzpvxF96SPHy"
   },
   "outputs": [],
   "source": [
    "# preprocessing the input image\n",
    "def process_image(roi_gray, img):\n",
    "        image_scaled = np.array(cv2.resize(roi_gray, (48, 48)), dtype=float)\n",
    "        image_processed = image_scaled.flatten()\n",
    "        image_processed = image_processed.reshape([-1, 48, 48, 1])\n",
    "\n",
    "        prediction = model.predict(image_processed)\n",
    "        emotion = smooth_emotions(prediction)\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img, \"Emotion: \" + emotion, (50, 450), font, 1, (0, 255, 255), 2)\n",
    "        cv2.imshow('img', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The above function performs a series of preprocessing steps on input image by reshaping and flattening. Then it feeds the processed image to the model for it to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting objects through webcam\n",
    "\n",
    "The below code is used to detect objects through webcam. To capture a video, we need to create a VideoCapture object. Its argument can be either the device index or the name of a video file. Device index is just the number to specify which camera. Normally one camera will be connected (as in my case). So I simply pass 0 (or -1). You can select the second camera by passing 1 and so on. After that, you can capture frame-by-frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JPx_vFlZST2T"
   },
   "outputs": [],
   "source": [
    "# detecting human faces using HAAR cascade\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "#cap = cv2.VideoCapture(0) # 0 for webcam\n",
    "cap = cv2.VideoCapture(\"../face_detection.mp4\") # input the name of your video file here\n",
    "\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        roi_gray = gray[y:y + h, x:x + w]\n",
    "        roi_color = img[y:y + h, x:x + w]\n",
    "        process_image(roi_gray, img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wthQNpF-7a1U"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "\n",
    "* After training the model on almost 600 epochs and tuning hyperparameters the training and testing accuracy came out to be 99.3% and 58.0% respectively.\n",
    "\n",
    "* But, the problem with VGG was as the epochs increases the loss was also increasing instead of decreasing. Also, the VGG19 architecture is very heavy and takes lot of computation power. So it was difficult to train VGG again and try to improve accuracy.\n",
    "\n",
    "* Below table summarizes the values and the score that we could produce using the respective combination.\n",
    " \n",
    "\n",
    "Model No. | training accuracy | testing accuracy\n",
    "-----------------|----------------|----------------------\n",
    "VGG19 | 99.3 % | 58.0%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "btuKsdP6Ck1b"
   },
   "source": [
    "## Contribution\n",
    "\n",
    "In the above analysis:\n",
    "\n",
    "- 60% of the work is done by us which includes\n",
    "  * VGG19 architecture implementation\n",
    "  * Live webcam code optimization\n",
    "\n",
    "- 40% of the work is taken from web, the links for which are cited below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rg8G0b6cDH5b"
   },
   "source": [
    "## Citations\n",
    "\n",
    "* For face detection - https://www.youtube.com/watch?v=PmZ29Vta7Vc\n",
    "\n",
    "* For VGG19 and ResNet - https://github.com/tflearn/tflearn/tree/master/examples/images\n",
    "\n",
    "* For tflearn - http://tflearn.org/tutorials/\n",
    "\n",
    "* Article on Facial Emotion Recognition using CNN - http://sefiks.com/2018/01/01/facial-expression-recognition-with-keras/\n",
    "\n",
    "* VGG19 CNN - https://www.mathworks.com/help/deeplearning/ref/vgg19.html;jsessionid=ccf9599bd865b423281a56299a68"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OzShatdODYU7"
   },
   "source": [
    "## License\n",
    "\n",
    "<font size=\"4\">MIT License</font>\n",
    "    \n",
    "<b>Copyright (c) 2019 RUPESH ACHARYA, PREETAM JAIN</b>\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "VGG19_v1.0.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
